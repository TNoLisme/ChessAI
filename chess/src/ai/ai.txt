
					MỤC LỤC
Giới thiệu
Tổng quan dự án
Thu thập dữ liệu
Tiền xử lý dữ liệu
Lựa chọn mô hình
Xây dựng mô hình
Huấn luyện mô hình
Đánh giá mô hình
Tối ưu hóa mô hình
Hướng phát triển mô hình trong tương lai
Tổng kết



Tổng quan dự án
Đặt vấn đề
Việc xây dựng một hệ thống trí tuệ nhân tạo (AI) cho cờ vua đạt trình độ mạnh (Elo ≥ 2200) là một nhiệm vụ đầy thách thức, đòi hỏi giải quyết đồng thời nhiều vấn đề kỹ thuật phức tạp. Cờ vua là một trò chơi chiến thuật với không gian trạng thái và cây tìm kiếm cực lớn, khiến việc đánh giá thế cờ và lựa chọn nước đi tối ưu trở nên khó khăn. Để đạt được trình độ Master (Elo ≥ 2200) trong các giải đấu nội bộ, hệ thống phải triển khai hiệu quả cả mô hình học sâu để ước lượng giá trị thế cờ lẫn các thuật toán tìm kiếm tinh vi để giảm thiểu sai sót trong việc đưa ra quyết định chiến lược. Ngoài ra, việc thiết kế AI còn phải đảm bảo các tiêu chí về trải nghiệm người dùng và giới hạn phần cứng trong khi vẫn cân bằng được chất lượng đánh cờ và hiệu năng thực tế của hệ thống.
Trong phạm vi phần cứng hạn chế – như chỉ sử dụng một máy tính cá nhân hoặc một máy chủ nhỏ – dự án yêu cầu tối ưu hóa mô hình học máy một cách nghiêm ngặt. Mạng thần kinh phải được thiết kế với kích thước và độ sâu phù hợp để đảm bảo vừa có khả năng đánh giá chính xác thế cờ, vừa không vượt quá công suất xử lý cho phép. Các giải pháp như giảm kích thước batch, nén mô hình hoặc chuyển đổi sang các kiến trúc nhẹ hơn đều được xem xét để hạn chế bộ nhớ và tính toán, đồng thời đảm bảo tốc độ suy luận (inference) đủ nhanh. Sự cân bằng giữa độ phức tạp của mô hình và giới hạn phần cứng là yếu tố quyết định để cho phép triển khai AI cờ vua ngay trên các hệ thống thông thường, từ đó nâng cao khả năng truy cập và ứng dụng thực tế.
Trải nghiệm người chơi là một yếu tố trọng tâm khác trong thiết kế hệ thống. Hệ thống AI cần đảm bảo thời gian phản hồi nhanh, lý tưởng nhất không quá 10 giây cho mỗi nước đi, nhằm giữ cho trải nghiệm chơi mượt mà và hạn chế thời gian chờ đợi. Giao diện người dùng (UI) phải được thiết kế trực quan, bao gồm bố cục bàn cờ rõ ràng, hiển thị thông tin cần thiết về thế cờ và thời gian bên cạnh. Một thành phần quan trọng của giao diện là khung lịch sử nước đi, giúp người chơi theo dõi các nước đã đi và phục vụ cho việc phân tích sau ván đấu. Hệ thống cũng phải có chức năng lưu ván đấu dưới định dạng PGN (Portable Game Notation) để người chơi có thể lưu lại hoặc chia sẻ ván cờ một cách thuận tiện. Tất cả những yêu cầu trên nhằm đảm bảo hệ thống AI không chỉ mạnh về mặt trí tuệ mà còn mang lại trải nghiệm sử dụng chuyên nghiệp và dễ tiếp cận cho người chơi.

Mục tiêu dự án
Mục tiêu chất lượng cho AI cờ vua là đạt được trình độ nội bộ (đánh giá Elo) xấp xỉ 2200 – tương đương với cấp độ Kiện tướng (Master) của con người. Để đạt được mục tiêu này, phương pháp huấn luyện chủ đạo là học có giám sát (supervised learning) trên tập dữ liệu lịch sử các ván cờ chất lượng cao. Cụ thể, dự án sử dụng các bộ dữ liệu PGN đã được thu thập và xử lý từ các nguồn lớn như Lichess hoặc Kaggle, bao gồm các ván cờ của cao thủ trên thế giới. Mạng nơ-ron tích chập (CNN) cơ bản sẽ được xây dựng để nhận diện và đánh giá các thế cờ dựa trên hình thức biểu diễn ma trận các quân cờ trên bàn. Thông qua việc cho mạng học trên hàng trăm ngàn ván cờ chất lượng cao, hệ thống sẽ học được các đặc trưng quyết định nước đi tốt cũng như quy tắc cơ bản của các chiến thuật chiến lược trong cờ vua. Kết quả thu được là một mô hình học sâu có khả năng cung cấp đánh giá ban đầu cho mỗi thế cờ với độ chính xác tương đối cao, làm nền tảng cho việc ra quyết định về nước đi tiếp theo.
Trong giai đoạn suy luận, hệ thống kết hợp cả mô hình học sâu và thuật toán tìm kiếm để đảm bảo hiệu quả và độ chính xác. Một chiến lược quan trọng là điều chỉnh kích thước batch cũng như giới hạn độ sâu của việc tìm kiếm theo mức phức tạp của thế cờ và tài nguyên tính toán hiện có. Hệ thống sẽ áp dụng các heuristic đã được kiểm chứng trong cờ vua như cắt tỉa alpha-beta để giảm bớt không gian tìm kiếm và tập trung vào các biến thể triển vọng nhất. Việc kết hợp giữa khả năng đánh giá nhanh của mạng CNN và sự linh hoạt của thuật toán tìm kiếm giúp tiết kiệm thời gian tính toán mà vẫn đảm bảo không bỏ sót các nước đi quan trọng. Ngoài ra, hệ thống được thiết kế để hoạt động ở hai chế độ chính: Người – Máy và Máy – Máy. Ở chế độ Người – Máy, người dùng có thể chơi trực tiếp với AI và nhận lại gợi ý nước đi trong thời gian thực, còn ở chế độ Máy – Máy, hệ thống có thể tự động cho AI thi đấu với chính nó để đánh giá tính ổn định và hiệu suất của mô hình dưới các thế cờ khác nhau.

Phạm vi và giới hạn
Phạm vi nghiên cứu của dự án được xác định rõ ràng để đảm bảo tính khả thi và tập trung. Dữ liệu huấn luyện được giới hạn ở các tập PGN đáng tin cậy và có sẵn công khai, loại bỏ việc tự tạo hoặc chơi tự động (self-play) như một phần của quy trình tạo dữ liệu mới. Về mặt công nghệ, hệ thống chủ yếu được xây dựng bằng ngôn ngữ Python với các framework học máy phổ biến như PyTorch hoặc TensorFlow, nhằm tận dụng khả năng triển khai mạng nơ-ron và tích hợp với các thư viện trợ giúp xử lý cờ vua. Ngoài ra, dự án không nhằm cạnh tranh trực tiếp với các engine cờ vua hàng đầu như Stockfish hay AlphaZero, vốn sử dụng các phương pháp tiên tiến như tìm kiếm Monte Carlo Tree Search hoặc kết hợp với dữ liệu tự sinh. Thay vào đó, mục tiêu của dự án là cân bằng giữa chất lượng đánh cờ (tức là đạt được Elo tương đối cao) và khả năng vận hành hiệu quả trên phần cứng tiêu chuẩn, từ đó có thể mở rộng hoặc nghiên cứu thêm trong tương lai.
Tóm lại, dự án hướng tới xây dựng một hệ thống AI cờ vua có chất lượng và hiệu năng thực tế hài hòa. Hệ thống sẽ cung cấp một nền tảng cơ bản để nghiên cứu và phát triển thêm về trí tuệ nhân tạo trong cờ vua, với trọng tâm là các giải pháp tối ưu hóa nguồn lực và trải nghiệm người dùng, đồng thời đạt được mục tiêu chất lượng chơi ở mức cao (Elo ≥ 2200) trong khả năng phần cứng giới hạn. Kết quả dự kiến là một ứng dụng AI cờ vua mạnh mẽ nhưng vẫn thực tiễn, đồng thời mở ra hướng đi cho các nghiên cứu tiếp theo về việc kết hợp các phương pháp học máy và thuật toán tìm kiếm trong môi trường tính toán hạn chế.
III. Thu thập và dữ liệu:
Dữ liệu là một trong những phần quan trọng nhất đối với một mô hình học máy có giám sát. Để xây dựng một mô hình AI Chess đạt Elo trên 2300, việc tìm kiếm, thu thập dữ liệu chất lượng cao là bước đầu tiên và quan trọng nhất. Dữ liệu cần thiết cho dự án bao gồm các ván cờ được chơi bởi người chơi có trình độ cao (Elo cao), cùng với các thông tin liên quan như lịch sử nước đi, kết quả trận đấu, thông tin về ván. Quá trình tìm kiếm và thu thập dữ liệu được thực hiện qua các bước sau:

1. Quá trình xác định và thu thập dữ liệu:
	Sau khi tìm kiếm dữ liệu về cờ vua, chúng tôi tìm được một số nguồn dữ liệu liên quan tới dự án như sau:
   - Lichess Database:  Lichess.org cung cấp cơ sở dữ liệu mở với hàng triệu ván cờ được chơi trực tuyến, bao gồm các ván cờ từ người chơi có Elo từ 2300 trở lên. Dữ liệu được lưu dưới dạng file PGN (Portable Game Notation), chứa thông tin chi tiết về các nước đi, thời gian, và kết quả trận đấu. Tuy nhiên, việc xử lý khối lượng dữ liệu lớn từ Lichess đòi hỏi thời gian và tài nguyên tính toán đáng kể.
   - FICS Database:Free Internet Chess Server (FICS) cung cấp các ván cờ từ người chơi ở nhiều cấp độ, với các file PGN được làm sạch để bao gồm các ván cờ tiêu chuẩn có ít nhất 4 nước đi. Dữ liệu này từng được sử dụng trong các dự án như Elo Predictor, nhưng không phải lúc nào cũng đảm bảo số lượng lớn các ván cờ từ người chơi có Elo cao (2300+).
   - Chess.com Database: Chess.com cung cấp dữ liệu ván cờ từ các giải đấu và trận đấu trực tuyến. Tuy nhiên, việc truy cập dữ liệu này thường yêu cầu quyền truy cập API trả phí hoặc mua cơ sở dữ liệu, điều này gây khó khăn trong việc sử dụng với ngân sách hạn chế của dự án.
   - Kaggle Datasets: Kaggle cung cấp các bộ dữ liệu liên quan đến cờ vua, chẳng hạn như bộ dữ liệu từ cuộc thi "Finding Elo". Những bộ dữ liệu này chứa thông tin về các ván cờ, Elo của người chơi, và kết quả trận đấu, đồng thời đã được làm sạch và xử lý trước để phù hợp với các dự án machine learning. Các bộ dữ liệu trên Kaggle thường đi kèm với tài liệu hướng dẫn và được cộng đồng kiểm chứng, giúp tiết kiệm thời gian trong giai đoạn tiền xử lý.

* Lựa chọn bộ dữ liệu: 
Sau khi cân nhắc, chúng tôi quyết định sử dụng Kaggle Datasets làm nguồn dữ liệu chính cho dự án AI Chess. Lý do lựa chọn gồm:
- Dữ liệu đã được xử lý sơ bộ: Bộ dữ liệu trên Kaggle, như bộ dữ liệu "Finding Elo", đã được làm sạch và định dạng sẵn (dưới dạng CSV), giúp giảm thời gian và công sức trong việc xử lý dữ liệu thô so với các file PGN từ Lichess hoặc FICS.
- Phù hợp với mục tiêu Elo > 2300: Bộ dữ liệu trên Kaggle bao gồm các ván cờ từ người chơi có Elo cao, với thông tin chi tiết về Elo của cả hai người chơi, nước đi, và kết quả trận đấu. Điều này đáp ứng yêu cầu xây dựng mô hình AI có khả năng học từ các ván cờ chất lượng cao.
- Dễ dàng truy cập và miễn phí: Kaggle cung cấp dữ liệu mở, dễ dàng tải xuống mà không cần API trả phí như Chess.com, phù hợp với ngân sách của dự án.
- Hỗ trợ từ cộng đồng: Các bộ dữ liệu trên Kaggle thường đi kèm với các notebook mẫu và thảo luận từ cộng đồng, giúp chúng tôi hiểu rõ cấu trúc dữ liệu và áp dụng các kỹ thuật phân tích phù hợp.
- Khối lượng dữ liệu vừa đủ: Bộ dữ liệu này trên Kaggle tuy không lớn bằng Lichess, nhưng vẫn cung cấp số lượng ván cờ lớn, đủ để huấn luyện một mô hình AI mạnh mẽ mà không gây quá tải tài nguyên tính toán.

Cụ thể, chúng tôi đã chọn bộ dữ liệu "Chess Games of Woman Grandmasters (2009 - 2021)”  từ Kaggle, chứa khoảng 200.000 ván cờ từ các người chơi có Elo trung bình từ 2000 trở lên. Dữ liệu này được lưu dưới dạng CSV, với các cột chính bao gồm `GameID`, `WhiteElo`, `BlackElo`, `Result`, và `Moves`. Để làm giàu dữ liệu, chúng tôi dự kiến sử dụng engine Stockfish để tạo thêm các bộ dữ liệu chất lượng cao cho dự án. Việc lựa chọn Kaggle Datasets không chỉ giúp tối ưu hóa thời gian và tài nguyên mà còn đảm bảo dữ liệu có chất lượng cao, phù hợp với mục tiêu phát triển một AI Chess đạt Elo trên 2300.

Ngoài việc sử dụng dữ liệu từ Kaggle, chúng tôi còn tự tạo thêm các bộ dữ liệu mới để tăng cường độ đa dạng và chất lượng của tập dữ liệu. Cụ thể, chúng tôi sử dụng Stockfish, một engine cờ vua mã nguồn mở nổi tiếng với thuật toán mạnh mẽ và khả năng mô phỏng các trình độ chơi khác nhau.Lý do sử dụng Stockfish để tạo dữ liệu:
- Chất lượng cao: Stockfish là một trong những engine cờ vua mạnh nhất thế giới, với Elo ước tính trên 3500 ở cấu hình tối ưu. Các ván cờ do Stockfish tạo ra phản ánh các chiến thuật và chiến lược chơi ở trình độ cao, phù hợp với mục tiêu xây dựng AI đạt Elo > 2300.
- Kiểm soát được Elo: Việc điều chỉnh mức Elo của Stockfish cho phép tạo ra các ván cờ với độ khó cụ thể, đảm bảo dữ liệu phù hợp với mục tiêu dự án.
- Đa dạng hóa dữ liệu: Dữ liệu từ Kaggle chủ yếu đến từ các ván cờ của con người, trong khi dữ liệu Stockfish cung cấp góc nhìn từ engine, giúp mô hình học được cả phong cách chơi của con người và các nước đi tối ưu của máy tính.
- Khắc phục hạn chế của dữ liệu con người: Các ván cờ từ Kaggle có thể chứa sai lầm (blunder) hoặc phong cách chơi không nhất quán. Dữ liệu từ Stockfish đảm bảo tính ổn định và chất lượng cao, đặc biệt trong các tình huống phức tạp.
Tóm lại, dữ liệu của chúng tôi bao gồm 1 bộ dữ liệu "Chess Games of Woman Grandmasters (2009 - 2021)”  từ Kaggle, 1 bộ dữ liệu  được tạo từ engine Stockfish.  Quá trình thu thập dữ liệu không chỉ đảm bảo khối lượng mà còn tập trung vào chất lượng, với việc ưu tiên các ván cờ từ người chơi có Elo cao và sử dụng các công cụ như Stockfish để làm giàu thông tin. Đây là nền tảng vững chắc cho các bước phân tích và xây dựng mô hình trong dự án.

IV. Phân tích và tiền xử lý dữ liệu:
1. Phân tích dữ liệu:
Phân tích dữ liệu là bước quan trọng để hiểu rõ đặc điểm của bộ dữ liệu, xác định các xu hướng, phân phối, và các vấn đề tiềm ẩn trước khi tiến hành tiền xử lý và xây dựng mô hình. Chúng tôi đã thực hiện phân tích dữ liệu trên 2 bộ dữ liệu tổng hợp, bao gồm 304.767 ván cờ từ Kaggle ("Chess Games of Woman Grandmasters (2009 - 2021)") và dự tính 50000 ván cờ tự tạo từ Stockfish.
Đối với một ván cờ, sẽ có rất nhiều những thông tin về ván đấu, tuy nhiên không phải tất cả chúng đều có ích cho mô hình học máy. Vì vậy chúng tôi chỉ phân tích dữ liệu dựa trên một số thông tin cần thiết sau: Elo của hai người chơi, lịch sử các nước đi của ván đấu. Các thông tin này là tiêu chuẩn cho việc phân tích và tiền xử lý dữ liệu sau này.

* Đối với bộ dữ liệu từ Kaggle:
- Bộ dữ liệu Kaggle được lưu dưới dạng CSV với các cột chính:  game_id ,  game_url ,  pgn ,  time_control ,  end_time ,  rated ,  time_class ,  rules ,  wgm_username , white_username ,  white_rating , white_result ,  black_username ,  black_rating ,  black_result. 
- Qua file dữ liệu CSV, chúng tôi nhận thấy rằng bộ dữ liệu này chứa các ván chơi với dữ liệu khá đa dạng. Phân phối một số thông tin cần thiết về bộ dữ liệu:
+)   Phân phối Elo: Trong bộ dữ liệu Kaggle, Elo người chơi tập trung nhiều từ 2000 đến khoảng 2500, với giá trị trung bình khoảng 2190.43, độ lệch chuẩn là 281.54.

+) Phân phối sự chênh lệch về Elo: Sự chênh lệch về Elo giữa hai người chơi không quá lớn, với giá trị trung bình là 113.77 và độ lệch chuẩn 175.53.

- Các vấn đề phát hiện:
+) Dữ liệu thiếu: Một số ván cờ trong dữ liệu Kaggle thiếu thông tin Elo của một trong hai người chơi, thông tin về lịch sử nước đi lưu ở cột ‘pgn’.
+) Dữ liệu không nhất quán: lịch sử nước đi được lưu ở cột ‘pgn’ nhưng chưa được xử lý, cần đưa về dạng Algebraic Notation, ký hiệu nước đi theo dạng tọa độ hàng-cột (ví dụ e2e4)

* Đối với bộ dữ liệu được tạo từ Stockfish:
Đây là bộ dữ liệu do chúng tôi tạo nên bằng cách cho hai mô hình của Stockfish chơi với nhau, sau đó lưu lại lịch sử ván cờ. Vì vậy nên bộ dữ liệu này có chất lượng cao và đảm bảo, việc xảy ra lỗi là rất hạn chế. Tuy nhiên để đảm bảo an toàn, lịch sử các ván cờ vẫn sẽ được kiểm tra cụ thể.

2. Tiền xử lý dữ liệu
Tiền xử lý dữ liệu là bước quan trọng để chuẩn bị bộ dữ liệu cho việc huấn luyện mô hình AI Chess. Quá trình này bao gồm làm sạch dữ liệu, chuẩn hóa dữ liệu, và tạo đặc trưng (Feature Engineering) để đảm bảo dữ liệu sẵn sàng cho các thuật toán học máy. Bộ dữ liệu ban đầu chứa thông tin về các ván cờ, chủ yếu dưới dạng chuỗi PGN (Portable Game Notation), bao gồm các chi tiết như nước đi, Elo của người chơi, kết quả ván cờ, và các metadata khác. Tuy nhiên, dữ liệu thô thường chứa các vấn đề như giá trị thiếu, định dạng không nhất quán, hoặc các ván cờ không đạt chất lượng mong muốn. Để xây dựng một mô hình học máy có thể chơi cờ vua với Elo cao, chúng tôi tập trung vào xử lý các thông tin liên quan đến Elo người chơi và lịch sử ván cờ.

* Làm sạch dữ liệu:
Làm sạch dữ liệu là bước tiền xử lý quan trọng nhằm loại bỏ các ván cờ không hợp lệ, thiếu thông tin, hoặc không đáp ứng tiêu chí chất lượng cao để huấn luyện mô hình AI cờ vua với mục tiêu đạt Elo trên 2300. Bộ dữ liệu Kaggle, mặc dù phong phú với 304,767 ván cờ, chứa nhiều vấn đề như thông tin thiếu, định dạng không nhất quán, hoặc các ván cờ có chất lượng thấp. Trong khi đó, dữ liệu từ Stockfish được coi là đáng tin cậy và không cần làm sạch thêm. Quy trình làm sạch dữ liệu trên bộ dữ liệu Kaggle được thực hiện như sau:
- Loại bỏ các ván cờ thiếu thông tin Elo hoặc lịch sử nước đi:
+) Các ván cờ không có thông tin về Elo được loại bỏ, vì Elo là yếu tố quan trọng để đánh giá chất lượng ván cờ.
+) Các ván cờ thiếu chuỗi nước đi PGN (Portable Game Notation) trong cột pgn hoặc có chuỗi PGN rỗng cũng bị loại bỏ, đảm bảo rằng mỗi ván cờ có lịch sử nước đi đầy đủ để phân tích.
- Kiểm tra ký hiệu PGN: Cột pgn được chuẩn hóa về dạng Algebraic Notation (ký hiệu đại số), một định dạng chuẩn để biểu diễn các nước đi cờ vua.  Mỗi chuỗi PGN được phân tích bằng thư viện python-chess để tái hiện ván cờ. Các ván cờ chứa nước đi không hợp lệ (ví dụ: nước đi không tuân theo luật cờ vua hoặc không thể tái hiện) được loại bỏ, đảm bảo tính chính xác của dữ liệu.
- Loại bỏ các ván cờ có số nước đi dưới 40: Phân tích cho thấy các ván cờ giữa các kỳ thủ có Elo cao và chênh lệch Elo nhỏ thường có trung bình khoảng 50 nước đi. Các ván cờ dưới 40 nước đi có khả năng thiếu thông tin trong cột pgn (ví dụ: chỉ ghi lại một phần ván cờ) hoặc kết thúc sớm do đầu hàng không phản ánh chiến lược đầy đủ.Việc loại bỏ các ván cờ này giúp tập trung vào các ván cờ có chiều sâu chiến thuật, phù hợp với mục tiêu huấn luyện mô hình.
- Loại bỏ các ván cờ có Elo dưới 2000:
+) Để xây dựng mô hình đạt Elo trên 2300, các ván cờ có người chơi với Elo dưới 2000 được coi là không cần thiết, vì chúng có thể chứa các nước đi không tối ưu, gây nhiễu cho mô hình.
+) Lọc các ván cờ có Elo của người chơi dưới 2000 đảm bảo rằng dữ liệu chỉ bao gồm các ván cờ chất lượng cao từ các kỳ thủ trình độ cao.

- Kết quả sau khi làm sạch bộ dữ liệu từ Kaggle:
+) Số lượng ván cờ giảm: Từ 304,767 ván cờ ban đầu, sau khi áp dụng các tiêu chí làm sạch, chỉ còn 204,518 ván cờ được giữ lại.
+) Chất lượng dữ liệu: Bộ dữ liệu sau làm sạch bao gồm các ván cờ có Elo của cả hai người chơi trên 2000 và ít nhất 40 nước đi, đảm bảo dữ liệu phản ánh các trận đấu chất lượng cao với chiến lược sâu sắc.
+) Tác động: Việc làm sạch này loại bỏ nhiễu, tăng cường tính nhất quán của dữ liệu, và tạo nền tảng cho các bước chuẩn hóa và tạo đặc trưng tiếp theo.

* Chuẩn hóa dữ liệu:
Chuẩn hóa dữ liệu là bước tiền xử lý nhằm chuyển đổi dữ liệu thô sau khi làm sạch thành định dạng số học phù hợp để huấn luyện mô hình học sâu. Quy trình chuẩn hóa dữ liệu được thiết kế để đảm bảo các đặc trưng đầu vào của mô hình có định dạng nhất quán, tối ưu cho tính toán và tương thích với kiến trúc mô hình. Các bước chuẩn hóa bao gồm:
- Chuẩn hóa định dạng số: Các giá trị số như số lượng nước đi mỗi ván được chuẩn hóa về khoảng (0, 1) bằng cách chia cho giá trị tối đa. Điều này giúp mô hình xử lý tốt hơn các giá trị số lớn và đảm bảo tính đồng nhất giữa các ván cờ có độ dài khác nhau.
- Chuyển đổi kiểu dữ liệu:
+) Tất cả các giá trị số  (chỉ số ô, số lượng nước đi) được chuyển thành kiểu float32 để giảm tiêu tốn bộ nhớ và tối ưu hóa hiệu suất tính toán. 
+) Các đặc trưng phân loại (như thông tin phong cấp) được mã hóa dưới dạng nhị phân (0.0 hoặc 1.0) để đảm bảo tính đồng nhất.





* Tạo đặc trưng:
Mô hình học máy của chúng tôi dựa trên dữ liệu là lịch sử nước đi của ván đấu, từ đó tạo ra các đặc trưng làm đầu vào input cho mô hình.Cụ thể quá trình tạo đặc trưng được diễn ra như sau: 
- Trạng thái bàn cờ (board):
+) Mô tả: Biểu diễn trạng thái bàn cờ tại mỗi nước đi dưới dạng tensor 8x8x12, với 12 kênh tương ứng với 6 loại quân cờ (pawn, knight, bishop, rook, queen, king) cho mỗi màu (trắng và đen).
+) Quy trình:
Từ lịch sử nước đi trong chuỗi PGN, sử dụng thư viện python-chess để tái tạo bàn cờ tại mỗi trạng thái. Bắt đầu từ vị trí khai cuộc tiêu chuẩn (FEN: rnbqkbnr/pppppppp/5n1p/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1), lần lượt áp dụng các nước đi để cập nhật bàn cờ.
Mỗi ô trên bàn cờ được ánh xạ vào tensor 8x8. Nếu ô chứa quân cờ, kênh tương ứng được gán 1.0; ô trống được gán 0.0. Ví dụ, pawn trắng ở e2 được mã hóa bằng 1.0 tại [6, 4, 0].
+) Tầm quan trọng: Đặc trưng này cung cấp thông tin không gian về vị trí các quân cờ, phản ánh cấu trúc bàn cờ tại mỗi thời điểm.
- Bên đi (side_to_move):
+) Mô tả: Giá trị đơn biểu diễn bên đang đi: 0 cho trắng, 1 cho đen.
+) Quy trình: Dựa trên trạng thái bàn cờ tái tạo, sử dụng thuộc tính board.turn từ python-chess để xác định bên đi (chess.WHITE → 0, chess.BLACK → 1).
+) Tầm quan trọng: Đặc trưng này xác định lượt chơi hiện tại, cung cấp ngữ cảnh chiến thuật quan trọng (ví dụ: trắng thường tấn công sớm, đen phản công).
- Quyền nhập thành (castling_rights):
+) Mô tả: Vector [trắng ngắn, trắng dài, đen ngắn, đen dài] với giá trị 1 nếu quyền nhập thành còn tồn tại, 0 nếu đã mất.
+) Quy trình: Từ bàn cờ tái tạo, sử dụng các hàm của python-chess để kiểm tra quyền nhập thành cho cả hai bên.
Ví dụ, nếu trắng vẫn có thể nhập thành ngắn và dài, đen đã mất cả hai quyền nhập thành ngắn và dài, vector là [1, 1, 0, 0].
+) Tầm quan trọng: Quyền nhập thành là yếu tố chiến lược quan trọng, đặc biệt trong khai cuộc và trung cuộc, ảnh hưởng đến việc bảo vệ vua hoặc tổ chức tấn công.
- Lịch sử 8 nước đi gần nhất (history):
+) Mô tả: Mã hóa tối đa 8 nước đi gần nhất dưới dạng danh sách các vector [from_square, to_square, captured_piece, special_move_type] ([ô hiện tại, ô đến, quân bị bắt, nhập thành]), sau đó được đệm để đạt độ dài cố định.
+) Quy trình: Từ lịch sử nước đi, trích xuất các nước đi trước trạng thái hiện tại (tối đa 8 nước). Mỗi nước đi được mã hóa:
from_square: Chỉ số ô bắt đầu (0–63), lấy từ nước đi UCI (ví dụ: "e2e4" → ô e2 = 12).
to_square: Chỉ số ô đích (0–63), ví dụ: ô e4 = 36.
captured_piece: Chỉ số loại quân bị bắt (0–1) hoặc -1 nếu không có quân bị bắt.
special_move_type: 1 nếu nước đi là nhập thành, 0 nếu không.
Nếu lịch sử ngắn hơn 8 nước (ví dụ: ở đầu ván cờ), các vị trí trước đó được điền bằng None và xử lý sau để tạo tensor đồng nhất.
+) Tầm quan trọng: Đặc trưng này cung cấp ngữ cảnh thời gian, phản ánh các chuỗi nước đi gần đây, như chiến thuật tấn công, phòng thủ, hoặc nhập thành.
- Số lượng nước đi (move_count):
+) Mô tả: Giá trị đơn biểu diễn số nước đi đã thực hiện trong ván cờ, đếm từ lịch sử nước đi.
+) Quy trình: Đếm số nước đi đã áp dụng từ chuỗi pgn cho đến trạng thái hiện tại.
+) Tầm quan trọng: Đặc trưng này phản ánh tiến độ ván cờ, giúp phân biệt các giai đoạn khác nhau (khai cuộc, trung cuộc, tàn cuộc).
- Giai đoạn ván cờ (game_phase):
+) Mô tả: Vector one-hot [khai cuộc, trung cuộc, tàn cuộc] biểu diễn giai đoạn ván cờ dựa trên tổng giá trị vật chất trên bàn cờ.
+) Quy trình: Tính tổng giá trị vật chất (total_material) bằng cách cộng giá trị của các quân cờ trên bàn cờ (pawn=1, knight=3, bishop=3, rook=5, queen=9, king=0).
Xác định giai đoạn:
Khai cuộc: total_material > 60 (nhiều quân còn lại, gần trạng thái ban đầu).
Trung cuộc: 20 ≤ total_material ≤ 60 (một số quân đã bị bắt, trò chơi phát triển).
Tàn cuộc: total_material < 20 (ít quân còn lại, tập trung vào chiếu hết).
Mã hóa thành vector one-hot: [1, 0, 0] cho khai cuộc, [0, 1, 0] cho trung cuộc, [0, 0, 1] cho tàn cuộc.
+) Tầm quan trọng: Đặc trưng này cung cấp ngữ cảnh chiến lược, giúp phân biệt các giai đoạn với các ưu tiên khác nhau (phát triển quân, trao đổi quân, hoặc kết thúc ván cờ).

* Nhãn đầu ra output:
- Output tổng quát: là tuple (from_square, to_square, is_promotion) biểu diễn nước đi tiếp theo, dùng để phân tích hoặc đánh giá chiến lược.
- Cách xây dựng:
+) Từ chuỗi pgn, lấy nước đi tiếp theo và chuyển thành tuple (from_square, to_square).
+) Kiểm tra phong cấp (is_promotion): Nếu quân di chuyển là pawn và ô đích nằm ở hàng cuối (hàng 7 cho trắng, hàng 0 cho đen), gán is_promotion = 1; ngược lại, gán 0.
+) Nhãn được lưu với định dạng (from_square, to_square, is_promotion) cho mỗi trạng thái.
- Mục tiêu: là nhãn đầu ra cho mỗi nước đi được thực hiện trong 1 ván cờ, từ đó giúp mô hình học được các cách để đưa ra một nước đi dựa trên trạng thái bàn cờ hiện tại và lịch sử một số nước đi trước đó 

Quy trình tạo đặc trưng cho input và nhãn đầu ra output đã chuyển đổi thành công dữ liệu thô từ lịch sử nước đi thành sáu đặc trưng (board, side_to_move, castling_rights, history, move_count, game_phase) và nhãn đầu ra (from_square, to_square, is_promotion). Đặc trưng board cung cấp thông tin không gian về vị trí quân cờ, history phản ánh ngữ cảnh thời gian của các nước đi gần đây, trong khi side_to_move, castling_rights, move_count, và game_phase bổ sung thông tin chiến lược về lượt chơi, quyền nhập thành, tiến độ, và giai đoạn ván cờ. Nhãn đầu ra hỗ trợ cho việc đưa ra các quyết định nước đi thực tế. 

Quá trình phân tích và tiền xử lý dữ liệu đã biến bộ dữ liệu thô từ Kaggle và Stockfish thành một tập dữ liệu chất lượng cao, sẵn sàng cho việc huấn luyện mô hình AI Chess. Phân tích dữ liệu giúp hiểu rõ phân phối Elo, đồng thời phát hiện các vấn đề cần xử lý. Tiền xử lý bao gồm làm sạch dữ liệu (loại bỏ giá trị thiếu, ván cờ không hợp lệ), chuẩn hóa dữ liệu (Elo, nước đi), và tạo đặc trưng input, nhãn đầu ra output để mô hình có khả năng học được cách đi đối với mỗi trạng thái bàn cờ.

V. Lựa chọn mô hình:
1. Phân tích dữ liệu và mục tiêu dự án:
* Phân tích dữ liệu:
- Đầu vào input: với mỗi 1 input sẽ có dạng tổng thể của đầu vào với cấu trúc một danh sách các tensor/vector, bao gồm:
+) board: (8, 8, 12)
+) history: (8, 4)
+) side_to_move: (1)
+) castling_rights: (4)
+) move_count: (1)
+) game_phase: (3)
- Đầu ra output: ứng với mỗi input sẽ có đầu ra output có dạng tổng thể của đầu ra với cấu trúc: Tuple (from_square, to_square, is_promotion)
+) from_square: Chỉ số (0–63).
+) to_square: Chỉ số (0–63).
+) is_promotion: Giá trị nhị phân (0 hoặc 1).

* Mục tiêu:
- Dự đoán nước đi tốt nhất tiếp theo với đầu ra: Dự đoán tuple (from_square, to_square, is_promotion) với độ chính xác cao, đảm bảo nước đi hợp lệ thông qua kiểm tra với thư viện python-chess.
- Xử lý dữ liệu phức tạp:
+) Tích hợp và xử lý các loại dữ liệu đầu vào: 
Không gian: Bàn cờ (8, 8, 12).
Thời gian: Lịch sử nước đi (8, 4).
Phi cấu trúc: Metadata (side_to_move, castling_rights, move_count, game_phase).
+) Học các mẫu chiến lược, ví dụ: phát triển quân trong khai cuộc, trao đổi trong trung cuộc, hoặc chiếu hết trong tàn cuộc.
- Huấn luyện mô hình hiệu quả trên tài nguyên tính toán hạn chế.
- Dễ dàng tích hợp với dữ liệu thực tế và có khả năng mở rộng nếu cần.
- Khả năng mở rộng:
+) Mô hình có cấu hình điều chỉnh được (số tầng, số filter, độ dài lịch sử) để phù hợp với dữ liệu hoặc tài nguyên khác nhau.
+) Dễ dàng tinh chỉnh nếu có thêm dữ liệu hoặc yêu cầu mới.
2. Các lựa chọn mô hình khả thi:
Dựa trên đặc điểm dữ liệu và mục tiêu, tôi xem xét các mô hình học máy truyền thống và học sâu sau:
a. Các mô hình học máy truyền thống: 
*  Decision Tree:
- Đặc điểm:
+) Mô hình học máy truyền thống, phân loại dựa trên cây quyết định.
+) Yêu cầu đặc trưng thủ công (ví dụ: số quân, quyền nhập thành).
- Ưu điểm:
+) Dễ triển khai, ít tốn tài nguyên.
+) Phù hợp với dữ liệu vector như metadata.
- Nhược điểm:
+) Không xử lý tensor bàn cờ (8, 8, 12) hoặc lịch sử (8, 4) mà không làm phẳng, mất thông tin không gian/thời gian.
+) Không gian trạng thái cờ vua quá lớn, hiệu suất kém.
* Random Forest:
- Đặc điểm:
+) Tổng hợp nhiều cây quyết định, cải thiện độ chính xác.
+) Xử lý đặc trưng thủ công, hỗ trợ đa đầu ra.
- Ưu điểm:
+) Giảm overfitting so với Decision Tree.
+) Phù hợp với metadata và đặc trưng bảng.
- Nhược điểm:
+) Làm phẳng tensor gây mất thông tin.
+) Không tận dụng cấu trúc không gian/thời gian, hiệu suất thấp.
* Gradient Boosting (XGBoost/LightGBM):
- Đặc điểm:
+) Sử dụng boosting để xây dựng mô hình mạnh từ cây quyết định.
+) Phù hợp với dữ liệu bảng, hỗ trợ đa đầu ra.
- Ưu điểm:
+) Hiệu suất cao với dữ liệu vector.
+) Xử lý được metadata và đặc trưng thủ công.
- Nhược điểm:
+) Làm phẳng bàn cờ/lịch sử mất thông tin.
+) Không hiệu quả với dữ liệu tensor phức tạp.

b. Các mô hình học sâu: 
* Mô hình dựa trên CNN (Convolutional Neural Network):
  - Đặc điểm:
+) Mạng nơ-ron học sâu, xử lý dữ liệu không gian (tensor).
+) Dùng tầng tích chập và residual block để học đặc trưng.
- Ưu điểm:
+) Phù hợp với bàn cờ (8, 8, 12), học vị trí quân/mối quan hệ không gian.
+) Residual block tăng hiệu quả học mẫu phức tạp.
- Nhược điểm:
+) Không xử lý lịch sử (8, 4) hoặc metadata.
+) Cần kết hợp với mô hình khác.
* Mô hình dựa trên  RNN (GRU/LSTM):
- Đặc điểm:
+) Mạng nơ-ron học sâu, xử lý dữ liệu chuỗi.
+) GRU (dùng trong dự án này) phù hợp chuỗi ngắn, ít tham số hơn LSTM.
- Ưu điểm:
+) Phù hợp với lịch sử nước đi (8, 4), học chiến thuật thời gian.
+) GRU hiệu quả, chi phí tính toán thấp.
- Nhược điểm:
+) Không xử lý bàn cờ hoặc metadata.
* Mô hình dựa trên MLP (Multi-Layer Perceptron):
- Đặc điểm:
+) Mạng nơ-ron học sâu, xử lý dữ liệu phi cấu trúc qua tầng fully connected.
+) Phù hợp với vector nhỏ.
- Ưu điểm:
+) Xử lý metadata (side_to_move, castling_rights, move_count, game_phase).
+) Dễ tích hợp với các mô hình khác.
- Nhược điểm:
+) Không tận dụng cấu trúc không gian/thời gian của bàn cờ/lịch sử.
* Mô hình dựa trên  CNN + GRU + MLP:
- Đặc điểm:
+) Mô hình học sâu kết hợp: CNN (bàn cờ), GRU (lịch sử), MLP (metadata).
+) Dự đoán đa đầu ra (from_square, to_square, is_promotion).
- Ưu điểm:
+) Tích hợp đầy đủ dữ liệu không gian, thời gian, phi cấu trúc.
+) Hỗ trợ đa đầu ra với loss riêng (Categorical Cross Entropy, Binary Cross Entropy).
+) Top-k suy luận đảm bảo nước đi hợp lệ.
- Nhược điểm:
+) Phức tạp hơn, cần điều chỉnh cẩn thận.
+) Tài nguyên tính toán cao hơn mô hình truyền thống:
* Mô hình Transformer:
- Đặc điểm:
+) Mạng nơ-ron học sâu, dùng attention để xử lý không gian/thời gian.
+) Phù hợp với dữ liệu phức tạp, chuỗi dài.
- Ưu điểm:
+) Học mối quan hệ phức tạp giữa bàn cờ, lịch sử, metadata.
+) Linh hoạt với nhiều loại dữ liệu.
- Nhược điểm:
+) Yêu cầu tài nguyên lớn, dư thừa cho lịch sử ngắn (8 nước) và bàn cờ có cấu trúc.
+) Huấn luyện phức tạp, không phù hợp tài nguyên hạn chế.
* Reinforcement Learning (AlphaZero):
- Đặc điểm:
+) Kết hợp học sâu (CNN) và self-play với Monte Carlo Tree Search.
+) Học từ ván cờ tự tạo, không cần dữ liệu thực tế.
- Ưu điểm:
+) Hiệu suất tốt, học chiến thuật tối ưu.
+) Không phụ thuộc dữ liệu thực tế.
- Nhược điểm:
+) Yêu cầu tài nguyên khổng lồ (về GPU/TPU).
+) Không tận dụng dữ liệu có sẵn.

3. Đánh giá và lựa chọn mô hình
Dựa trên phân tích, chúng tôi đề xuất mô hình kết hợp (CNN + GRU + MLP) vì các lý do sau:
* Phù hợp với cấu trúc dữ liệu:
- CNN với residual block là tối ưu để xử lý bàn cờ (8x8x12), học các mẫu không gian phức tạp như vị trí quân cờ và mối quan hệ giữa chúng.
- GRU phù hợp để xử lý lịch sử nước đi (8 bước), vì nó hiệu quả với chuỗi ngắn và có chi phí tính toán thấp hơn LSTM.
- MLP là lựa chọn tự nhiên để xử lý metadata, vì các đặc trưng này có kích thước nhỏ và không có cấu trúc không gian hoặc thời gian.
* Hỗ trợ dự đoán đa đầu ra tốt:
- Mô hình dự đoán đồng thời from_square, to_square và is_promotion, với các hàm loss riêng (Categorical Cross Entropy cho from_square/to_square, Binary Cross Entropy cho is_promotion).
- Phản ánh bản chất bài toán cờ vua, nơi mỗi nước đi bao gồm nhiều khía cạnh cần dự đoán chính xác.
* Hiệu quả tính toán:
- Tham số cấu hình có thể giúp chúng tôi cân bằng giữa độ chính xác và chi phí tính toán.
- Regularization L2, dropout, và batch normalization giảm overfitting và tăng tốc độ hội tụ.
- Callback ReduceLROnPlateau và EarlyStopping giúp đảm bảo tối ưu hóa hiệu quả.
* Tận dụng dữ liệu thực tế:
- Mô hình hoạt động được với dữ liệu thực tế từ các ván cờ, phù hợp với dữ liệu được tiền xử lý như trên.
- Không yêu cầu dữ liệu tự tạo như Reinforcement Learning, giảm chi phí và thời gian chuẩn bị.
* Khả năng mở rộng:
- Cấu hình mô hình (số residual block, số filter, độ dài lịch sử) có thể điều chỉnh để phù hợp với tài nguyên hoặc yêu cầu cụ thể.
- Có thể tinh chỉnh thêm nếu có dữ liệu hoặc tài nguyên mới.

	Chúng tôi lựa chọn mô hình trên là nhờ vào những đặc điểm phù hợp của chúng trong dự án của chúng tôi, ngoài ra các mô hình khác không phù hợp, có những hạn chế nhất định như sau:
- Decision Tree: Không thể xử lý dữ liệu phức tạp như bàn cờ hoặc lịch sử nước đi mà không cần thiết kế đặc trưng thủ công. Hiệu suất kém do không gian trạng thái cờ vua quá lớn.
- Random Forest: Dù cải thiện so với Decision Tree, vẫn yêu cầu đặc trưng thủ công và không tận dụng được cấu trúc không gian/thời gian của dữ liệu, dẫn đến hiệu suất thấp hơn học sâu.
- Gradient Boosting (XGBoost/LightGBM): Phù hợp với dữ liệu bảng, nhưng không hiệu quả với dữ liệu bàn cờ hoặc lịch sử nước đi. Việc làm phẳng dữ liệu gây mất thông tin không gian, giảm độ chính xác.
- CNN độc lập: Không xử lý được lịch sử nước đi hoặc metadata, mất thông tin về diễn biến ván cờ.
- RNN/GRU độc lập: Không phù hợp để xử lý bàn cờ hoặc metadata, giảm hiệu suất tổng thể.
- MLP độc lập: Không tận dụng cấu trúc không gian của bàn cờ hoặc mối quan hệ thời gian của lịch sử nước đi.
- Transformer: Yêu cầu tài nguyên tính toán lớn, không cần thiết cho lịch sử nước đi ngắn và bàn cờ có cấu trúc rõ ràng.
- RL (AlphaZero): Yêu cầu tài nguyên khổng lồ và không tận dụng dữ liệu thực tế, không khả thi với tài nguyên hạn chế.

* Kết luận:
Mô hình kết hợp CNN + GRU + MLP là lựa chọn tối ưu cho dự án AI cờ vua, vì nó phù hợp với cấu trúc dữ liệu (bàn cờ, lịch sử nước đi, metadata), hỗ trợ dự đoán đa đầu ra, và cân bằng giữa hiệu suất và chi phí tính toán. So với các mô hình học máy truyền thống (Decision Tree, Random Forest, Gradient Boosting), mô hình này vượt trội nhờ khả năng xử lý dữ liệu không gian và thời gian phức tạp. Các kỹ thuật như residual block, regularization, và callback đảm bảo mô hình đạt hiệu quả cao, đáp ứng tốt các mục tiêu của dự án.

VI. Xây dựng kiến trúc mô hình:
Để xây dựng mô hình, chúng tôi thiết kế kiến trúc chi tiết, phân tích từng module, giải thích lý do lựa chọn, và đảm bảo tối ưu hóa cho tài nguyên hạn chế. Mô hình được triển khai bằng TensorFlow/Keras, với các tầng được cấu hình để học các mẫu chiến thuật phức tạp của cờ vua.

1. Đầu vào và đầu ra của mô hình
- Đầu vào:
+) board: Tensor (batch_size, 8, 8, 12).
+) history: Tensor (batch_size, 8, 4).
+) side_to_move: Tensor (batch_size, 1).
+) castling_rights: Tensor (batch_size, 4).
+) move_count: Tensor (batch_size, 1).
+) game_phase: Tensor (batch_size, 3).
Các đầu vào này phản ánh đầy đủ trạng thái ván cờ, từ cấu trúc không gian (board), diễn biến thời gian (history), đến ngữ cảnh chiến lược (metadata).
- Đầu ra:
+) from_square: Tensor (batch_size, 64), softmax cho xác suất 64 ô.
+) to_square: Tensor (batch_size, 64), softmax cho xác suất 64 ô.
+) is_promotion: Tensor (batch_size, 1), sigmoid cho xác suất phong cấp.
Softmax phù hợp cho bài toán phân loại (64 ô), sigmoid phù hợp cho phân loại nhị phân (phong cấp), phản ánh bản chất đa đầu ra của bài toán. Mục tiêu chính ở đây là ánh xạ trạng thái ván cờ sang nước đi hợp lệ, tối ưu hóa cả ba đầu ra đồng thời.

2. Kiến trúc chi tiết:
Mô hình được chia thành ba module xử lý riêng (CNN, GRU, MLP) và một module kết hợp để dự đoán. Dưới đây là thiết kế chi tiết, với phân tích lý do cho từng lựa chọn.
2.1 Module xử lý bàn cờ (CNN):
Mục đích: Trích xuất đặc trưng không gian từ tensor bàn cờ (8, 8, 12), học các mẫu chiến thuật như vị trí quân, cấu trúc pawn, mối đe dọa, hoặc phối hợp giữa các quân. Chúng tôi xây dựng thiết kế với các thành phần như sau:
* Tầng tích chập khởi tạo:
- Layer: Conv2D (64 filter, kernel_size=(3, 3), padding='same').
- Phân tích cụ thể:
+) Chúng tôi dùng Kernel 3x3 vì phù hợp để học các mẫu cục bộ trên bàn cờ (ví dụ: quân gần nhau, như vua và xe trong nhập thành). Kernel nhỏ hơn (1x1) thiếu ngữ cảnh, lớn hơn (5x5) tăng chi phí tính toán.
+) 64 filter: Điểm khởi đầu hợp lý để học đa dạng đặc trưng (như vị trí quân, mối đe dọa), cân bằng giữa độ phức tạp và tài nguyên. Các mô hình cờ vua như AlphaZero thường dùng 64–256 filter.
+) Padding='same': Giữ kích thước đầu ra (8, 8), đảm bảo không mất thông tin ở rìa bàn cờ.
- Regularization: L2 (1e-4) để giảm overfitting, vì bàn cờ có nhiều mẫu phức tạp với nhiều trạng thái.
- Batch Normalization: Chuẩn hóa đầu ra để ổn định huấn luyện, giảm phụ thuộc vào giá trị khởi tạo trọng số.
- Activation: ReLU để thêm phi tuyến, giúp học các mẫu không gian phức tạp (như mối đe dọa từ quân xa).
- Đầu ra: Tensor (batch_size, 8, 8, 64).

* Residual Blocks:
- Số lượng: 8 blocks.
- Cấu trúc mỗi block:
+) Conv2D (64 filter, kernel_size=(3, 3), padding='same', L2=1e-4).
+) BatchNormalization và ReLU.
+) Conv2D thứ hai (64 filter, kernel_size=(3, 3), padding='same', L2=1e-4).
+) BatchNormalization.
+) Shortcut connection: Cộng đầu vào block với đầu ra Conv2D thứ hai.
+) ReLU sau cùng.
- Phân tích cụ thể:
+) Residual connections: Cho phép mạng sâu hơn mà không gặp vanishing gradient, học các mẫu chiến thuật phức tạp (như phối hợp quân ở khoảng cách xa). Các mô hình như ResNet và AlphaZero chứng minh hiệu quả của residual blocks.
+) 8 blocks: Đủ sâu để học đặc trưng cấp cao (như kế hoạch tấn công dài hạn), nhưng không quá lớn để tránh vượt tài nguyên. AlphaZero dùng 10–20 blocks, nhưng với tài nguyên hạn chế, 8 là tối ưu.
+) 64 filter: Giữ số filter nhất quán để duy trì kích thước đặc trưng, giảm chi phí tính toán.
+) L2=1e-4: Giảm overfitting, vì dữ liệu cờ vua có nhiều biến thể.
+) Batch Normalization: Ổn định gradient qua các block, tăng tốc hội tụ.
+) ReLU: Đảm bảo phi tuyến sau mỗi block.
- Đầu ra: Tensor (batch_size, 8, 8, 64).

* Global Average Pooling:
- Layer: GlobalAveragePooling2D.
- Phân tích cụ thể:
+) Chuyển tensor (8, 8, 64) thành vector (64,) để tổng hợp đặc trưng không gian (ví dụ: mức độ uy hiếp tổng thể của quân đối phương).
+) So với Flatten (tạo vector 8864=4096), Global Average Pooling giảm số tham số, tránh overfitting, và giữ thông tin quan trọng.
+) Phù hợp với bài toán cờ vua, nơi đặc trưng tổng thể (như kiểm soát trung tâm) quan trọng hơn thông tin cục bộ ở từng ô.
- Đầu ra: Vector (batch_size, 64).

* Tổng quát:
Module này biến tensor bàn cờ thành vector đặc trưng không gian, biểu diễn các mẫu chiến thuật như cấu trúc pawn, vị trí vua, hoặc mối đe dọa. CNN là chuẩn mực cho dữ liệu không gian (như hình ảnh hoặc bàn cờ), được chứng minh trong các mô hình cờ vua (AlphaZero, Leela Chess). Residual blocks tăng độ sâu mà không làm mất thông tin, phù hợp với không gian trạng thái lớn. Global Average Pooling giảm chiều hiệu quả, phù hợp với tài nguyên hạn chế.

2.2. Module xử lý lịch sử nước đi (GRU):
Mục đích: Trích xuất đặc trưng thời gian từ tensor lịch sử (8, 4), học các mẫu chiến thuật như chuỗi tấn công, phòng thủ, hoặc nhập thành. Sau đây là các thành phần của module này:
* Tầng GRU:
- Layer: GRU (32 đơn vị, return_sequences=False).
+) GRU vs LSTM: GRU có ít tham số hơn (3 cổng so với 4 cổng của LSTM), phù hợp với chuỗi ngắn (8 nước), giảm chi phí tính toán. LSTM mạnh hơn với chuỗi dài, nhưng không cần thiết ở đây.
+) 32 đơn vị: Đủ để học các mẫu thời gian cơ bản (như chuỗi di chuyển của quân mã hoặc kế hoạch nhập thành), nhưng không quá lớn để tránh phức tạp hóa.
+) return_sequences=False: Lấy đầu ra cuối cùng, tổng hợp thông tin từ 8 nước đi, vì mục tiêu là dự đoán nước đi tiếp theo, không cần toàn bộ chuỗi.
- Regularization: L2 (1e-4) để giảm overfitting, vì lịch sử có thể có các mẫu lặp lại.
- Đầu ra: Vector (batch_size, 32).

* Tầng Dense:
- Layer: Dense (16 đơn vị, ReLU, L2=1e-4).
+) Giảm chiều từ 32 xuống 16 để học đặc trưng cấp cao hơn (như xu hướng tấn công), giảm số tham số khi kết hợp với các module khác.
+) ReLU thêm phi tuyến để học các mối quan hệ phức tạp.
+) L2=1e-4 tiếp tục kiểm soát overfitting.
- Đầu ra: Vector (batch_size, 16).

* Tổng quan:
- Module này biến tensor lịch sử thành vector đặc trưng thời gian, biểu diễn các mẫu như chuỗi di chuyển lặp lại hoặc chiến thuật nhập thành.
- Lý do lựa chọn:
+) GRU là lựa chọn tối ưu cho chuỗi ngắn, hiệu quả hơn Transformer (quá nặng) và MLP (không xử lý thời gian).
+) 32 đơn vị và tầng Dense (16) cân bằng giữa khả năng học và chi phí tính toán.
+) Phù hợp với dữ liệu lịch sử (8 nước), được chứng minh trong các bài toán chuỗi như phân tích văn bản hoặc dự đoán hành động.

2.3. Module xử lý metadata (MLP)
Mục đích: Trích xuất đặc trưng chiến lược từ metadata (side_to_move, castling_rights, move_count, game_phase), tổng cộng 9 chiều. Chúng tôi xây dựng module với các thành phần như sau:
* Concatenate:
- Layer: Concatenate các vector: side_to_move (1,), castling_rights (4,), move_count (1,), game_phase (3,).
+) Tạo vector thống nhất (9,) để xử lý đồng thời tất cả metadata.
+) Metadata có kích thước nhỏ, không cần xử lý riêng từng thành phần.
- Đầu ra: Vector (batch_size, 9).

* Tầng Dense 1:
- Layer: Dense (16 đơn vị, ReLU, L2=1e-4).
+) Tăng chiều từ 9 lên 16 để học các mối quan hệ giữa metadata (ví dụ: quyền nhập thành ảnh hưởng đến giai đoạn ván cờ).
+) ReLU thêm phi tuyến, giúp học các mẫu chiến lược như ưu tiên nhập thành trong khai cuộc.
+) L2=1e-4 giảm overfitting, vì metadata có ít chiều nhưng quan trọng.
- Đầu ra: Vector (batch_size, 16).

* Tầng Dense 2:
- Layer: Dense (8 đơn vị, ReLU, L2=1e-4).
+) Giảm chiều xuống 8 để học đặc trưng cấp cao hơn, giữ đầu ra nhỏ để dễ kết hợp với CNN/GRU.
+) ReLU và L2 tiếp tục đảm bảo phi tuyến và kiểm soát overfitting.
- Đầu ra: Vector (batch_size, 8).

* Tổng quan:
- Module này biến metadata thành vector đặc trưng chiến lược, biểu diễn các yếu tố như lượt đi, quyền nhập thành, hoặc giai đoạn ván cờ.
- Phân tích lựa chọn:
+) MLP là lựa chọn tự nhiên cho dữ liệu vector nhỏ (9 chiều), nhẹ và hiệu quả so với CNN/GRU.
+) Hai tầng Dense (16→8) đủ để học các mối quan hệ chiến lược mà không làm phức tạp mô hình.
+) Phù hợp với metadata phi cấu trúc, bổ sung ngữ cảnh cho bàn cờ và lịch sử.

2.4. Kết hợp đặc trưng và dự đoán đầu ra
Mục đích: Kết hợp đặc trưng từ CNN (bàn cờ), GRU (lịch sử), MLP (metadata) để dự đoán (from_square, to_square, is_promotion).
* Concatenate:
- Layer: Concatenate các vector: CNN (64,), GRU (16,), MLP (8,).
+) Tạo vector thống nhất (88,) chứa thông tin không gian, thời gian, và chiến lược.
+) Concatenate là cách đơn giản và hiệu quả để tích hợp đặc trưng từ các nguồn khác nhau.
- Đầu ra: Vector (batch_size, 88).

* Tầng xử lý chung:
- Dense 1: Dense (64 đơn vị, L2=1e-4).
+) Giảm chiều từ 88 xuống 64 để học các mối quan hệ giữa đặc trưng (ví dụ: vị trí quân kết hợp với lịch sử tấn công).
+) 64 đơn vị phù hợp để học đặc trưng tổng hợp mà không quá lớn.
- Batch Normalization: Ổn định huấn luyện, giảm ảnh hưởng của các đặc trưng có quy mô khác nhau.
- ReLU: Thêm phi tuyến để học các mẫu phức tạp.
- Dropout (0.3): Ngẫu nhiên bỏ 30% nơ-ron trong huấn luyện để giảm overfitting, đặc biệt quan trọng khi kết hợp nhiều đặc trưng.
- Dense 2: Dense (64 đơn vị, L2=1e-4).
+) Học thêm đặc trưng cấp cao, chuẩn bị cho dự đoán đa đầu ra.
+) Giữ 64 đơn vị để duy trì thông tin phong phú.
- Batch Normalization, ReLU, Dropout (0.3): Tương tự để ổn định và giảm overfitting.
- Đầu ra: Vector (batch_size, 64).

* Tầng đầu ra:
- from_square: Dense (64, softmax).
+) Dự đoán xác suất trên 64 ô, softmax đảm bảo tổng xác suất bằng 1.
+) Phù hợp với bài toán phân loại (chọn ô bắt đầu).
- to_square: Dense (64, softmax).
+) Tương tự, dự đoán ô đích.
+) Softmax độc lập cho to_square đảm bảo mô hình học riêng các mẫu di chuyển.
- is_promotion: Dense (1, sigmoid).
+) Dự đoán xác suất phong cấp (0–1), sigmoid phù hợp với phân loại nhị phân.
+) Tách riêng để tối ưu hóa độc lập với các đầu ra phân loại.
- Đầu ra:
+) from_square: (batch_size, 64).
+) to_square: (batch_size, 64).
+) is_promotion: (batch_size, 1).

* Tổng quan:
- Module này tích hợp đặc trưng từ ba nguồn, học các mẫu tổng hợp để dự đoán nước đi chính xác.
+) Concatenate và hai tầng Dense cân bằng giữa khả năng học mối quan hệ phức tạp và chi phí tính toán.
+) Dropout (0.3) và L2 (1e-4) là tiêu chuẩn để giảm overfitting trong mạng sâu.
+) Đầu ra tách biệt (from_square, to_square, is_promotion) phản ánh bản chất đa nhiệm của bài toán, cho phép tối ưu hóa riêng từng đầu ra.

3. Hàm mất mát và chỉ số đánh giá
- Hàm mất mát:
+) from_square: Categorical Cross Entropy, phân loại 64 lớp (64 ô), Cross Entropy đo lường sai lệch giữa xác suất dự đoán và nhãn thật.
+) to_square: Categorical Cross Entropy, tương tự, đảm bảo học riêng các mẫu di chuyển đến ô đích.
+) is_promotion: Binary Cross Entropy, phân loại nhị phân (phong cấp hay không), Binary Cross Entropy phù hợp để tối ưu hóa xác suất 0–1.
+) Tổng mất mát: Tổng của ba hàm mất mát, không cần trọng số vì các đầu ra có tầm quan trọng ngang nhau.
Việc tách hàm mất mát cho phép mô hình tập trung vào từng nhiệm vụ, phản ánh bản chất đa đầu ra của bài toán.
- Chỉ số đánh giá:
+) from_square: Accuracy, Top K Categorical Accuracy (k=3). Accuracy đo tỷ lệ dự đoán đúng ô bắt đầu. Còn Top-3 accuracy đánh giá khả năng đề xuất các ô gần đúng, quan trọng trong cờ vua vì nhiều nước đi có thể tốt tương đương.
+) to_square: Accuracy, Top K Categorical Accuracy (k=3). Tương tự, đảm bảo đánh giá độc lập ô đích.
+) is_promotion: Accuracy. Đơn giản và trực tiếp cho phân loại nhị phân.
Các chỉ số này phản ánh hiệu suất thực tế của mô hình, đặc biệt top-3 accuracy giúp đánh giá khả năng đề xuất nước đi tốt trong bối cảnh cờ vua.

4. Tối ưu hóa
* Optimizer: Adam với learning rate khởi tạo 0.001.
- Adam kết hợp momentum và RMSProp, tự động điều chỉnh learning rate dựa trên gradient, hội tụ nhanh và ổn định.
- Learning rate 0.001 là giá trị tiêu chuẩn cho mạng sâu, phù hợp với bài toán cờ vua có dữ liệu phức tạp.
* Callback:
- ReduceLROnPlateau với cấu hình: Monitor=val_loss, factor=0.5, min_lr=1e-6, patience=3.
+) Giảm learning rate khi val_loss không cải thiện sau 3 epoch, giúp mô hình thoát khỏi các điểm dừng cục bộ.
+) Min_lr=1e-6 đảm bảo learning rate không giảm quá thấp, vẫn có thể học.
- EarlyStopping với cấu hình: Monitor=val_loss, patience=10, restore_best_weights=True.
+) Dừng huấn luyện nếu val_loss không cải thiện sau 10 epoch, tiết kiệm thời gian trên tài nguyên hạn chế.
+) restore_best_weights đảm bảo giữ mô hình tốt nhất, tránh mất kết quả do huấn luyện quá lâu.
- ModelCheckpoint: Lưu mô hình tốt nhất dựa trên val_loss, đảm bảo lưu mô hình tối ưu để sử dụng hoặc tinh chỉnh sau này.
- Phân tích tổng thể:
+) Adam và các callback này là bộ công cụ tiêu chuẩn cho mạng sâu, được sử dụng trong các mô hình cờ vua như Alpha Zero.
+) Chúng tối ưu hóa hiệu quả huấn luyện, giảm thời gian và tài nguyên, đặc biệt quan trọng khi RAM bị giám sát qua psutil.

5. Cấu hình siêu tham số:
- filters_conv: 64 (CNN khởi tạo): 64 filter đủ để học đa dạng đặc trưng không gian, cân bằng với tài nguyên hạn chế. Các mô hình như AlphaZero dùng 128–256, nhưng 64 phù hợp hơn ở đây.
- filters_res: 64 (residual blocks): Giữ nhất quán với Conv2D khởi tạo, đảm bảo tính liên tục của đặc trưng qua các block.
- num_res_blocks: 8. 8 block cung cấp độ sâu vừa đủ để học mẫu phức tạp, nhưng không quá lớn để tránh vượt RAM. AlphaZero dùng 10–20, nhưng tài nguyên hạn chế cần giảm xuống.
-mlp_units: 64 (tầng xử lý chung): 64 đơn vị phù hợp để học đặc trưng tổng hợp từ các module, không quá lớn để tránh phức tạp hóa.
- dropout_rate: 0.3. 30% dropout là giá trị tiêu chuẩn để giảm overfitting, đặc biệt khi kết hợp nhiều đặc trưng.
- l2_reg: 1e-4: Giá trị nhỏ nhưng hiệu quả để kiểm soát overfitting, phổ biến trong mạng sâu.
Các siêu tham số này được chọn dựa trên kinh nghiệm từ các mô hình cờ vua (AlphaZero, Leela Chess) mà chúng tôi tham khảo được và điều chỉnh cho tài nguyên hạn chế. Chúng đảm bảo mô hình học hiệu quả, tổng quát hóa tốt, và không vượt giới hạn RAM.


